{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Efficiency \n",
    "### Matias Bayas-Erazo\n",
    "\n",
    "This notebook gives some tips to improve the speed of programs. After introducing vectorization, it deals with some problems that are harder to vectorize. \n",
    "\n",
    "#### 1. Vectorizing\n",
    "\n",
    "Suppose we want to maximize the function $f(x,y)$ over $[-a,a] \\times [-a, a]$ where $a = 3$ and $f$ is given by:\n",
    "\n",
    "$$f(x,y) = \\frac{\\cos(x^2 + y^2)}{1 + x^2 + y^2}$$\n",
    "\n",
    "The following code implements a naive maximization routine where we do a grid search over the square to find the maximum value of $f$ over the square:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999981964109\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def f(x,y):\n",
    "    return np.cos(x**2 + y**2)/(1 + x**2 + y**2)\n",
    "\n",
    "grid = np.linspace(-3,3,1000)\n",
    "m = -np.inf\n",
    "\n",
    "for x in grid:\n",
    "    for y in grid:\n",
    "        z = f(x,y)\n",
    "        if z > m:\n",
    "            m = z\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is a vectorized version of the code above, which runs orders of magnitude faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99998196410857465"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x,y):\n",
    "    return np.cos(x**2 + y**2)/(1 + x**2 + y**2)\n",
    "\n",
    "grid = np.linspace(-3,3,1000)\n",
    "f = np.vectorize(f)\n",
    "f(grid,grid).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Numba\n",
    "\n",
    "When possible, it is always a good idea to vectorize your code. But some problems are harder to vectorize. For example, let's try to generate the trajectory of the following difference equation:\n",
    "\n",
    "$$ x_{t+1} = 4x_t(1-x_t) $$ \n",
    "\n",
    "As a first pass, consider the function gen_diff which generates the trajectory of our difference equation taking as argument the desired length of the path and the initial value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_diff(x_0, T):\n",
    "    \n",
    "    # List to store values:\n",
    "    x_values = np.empty(T)\n",
    "    \n",
    "    # Initial value:\n",
    "    x_values[0] = x_0\n",
    "    \n",
    "    for i in range(T-1):\n",
    "        x_values[i+1] = 4*x_values[i]*(1-x_values[i])\n",
    "    \n",
    "    return x_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not obvious how we can vectorize this code in order to imprtove efficieny. But we can speed this up using Numba, a package that automatically compiles functions into native machine code, helping run the code faster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "gen_diff_numba = jit(gen_diff) # Creates a compiled version of gen_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now time and compare the two functions using identical initial conditions and time series lengths:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 88.6 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit gen_diff(0.1, int(10**5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 976.55 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 3: 205 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit gen_diff_numba(0.1, int(10**5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first run is slower because of compilation, if we run the same thing again we get no\n",
    "warning message and realize that the compiled function increases speed by two orders of magnitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 218 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit gen_diff_numba(0.1, int(10**5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't really need a separate name for the function, we can just compile using numba with the '@' decorator notation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def gen_diff(x_0, T):\n",
    "    \n",
    "    # List to store values:\n",
    "    x_values = np.empty(T)\n",
    "    \n",
    "    # Initial value:\n",
    "    x_values[0] = x_0\n",
    "    \n",
    "    for i in range(T-1):\n",
    "        x_values[i+1] = 4*x_values[i]*(1-x_values[i])\n",
    "    \n",
    "    return x_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 434.00 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000 loops, best of 3: 218 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit gen_diff(0.1, int(10**5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Cython\n",
    "\n",
    "Another alternative is Cython which allows us to build fast compiled code that can be used from Python. In Cython, we add type definitions directly to our code. Thus, we can think of it as Python with type definitions. We start with the following example. Suppose that for a given $\\alpha$ and $n$, we want to compute:\n",
    "\n",
    "$$ \\sum_{i=0}^n \\alpha^i $$\n",
    "\n",
    "Assume we forgot the formula for geometric sums and hence we have to rely on a loop. Consider the following Python code that does this for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def geo_sum(alpha, n):\n",
    "    \n",
    "    sum = 0\n",
    "    for i in range(n):\n",
    "        sum = sum + alpha**i\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now carry out the Cython implementation of the same program written above. We begin by loading the Cython extension in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now execute the following Cython code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "def geo_sum_cython(double alpha, int n):\n",
    "    cdef double sum = 0\n",
    "    cdef int i\n",
    "    for i in range(n):\n",
    "        sum = sum + alpha**i\n",
    "    return sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, cdef is a keyword indicating variable declaration and is followed by a type. The first line of the cell, %%cython, it's a Jupyter cell magic indicating the beginning of Cython code. Let's now compare the two functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 119 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit geo_sum(0.99,int(10**6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 16.4 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit geo_sum_cython(0.99,int(10**6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having introduced basic Cython notation, let's go back to the example on generating a time path for the following difference equation in order to get a grasp of Cython with NumPy arrays. Recall the difference equation was given by:\n",
    "\n",
    "$$ x_{t+1} = 4x_t ( 1 - x_t) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np \n",
    "\n",
    "def gen_cython1(double x_0, int T):\n",
    "    cdef int i\n",
    "    x = np.empty(T, float)\n",
    "    x[0] = x_0\n",
    "    for i in range(T-1):\n",
    "        x[i+1] = 4*x[i]*(1-x[i])\n",
    "    return np.asarray(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 57.3 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit gen_cython1(0.1, int(10**5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the performance is dissapointing, nothing like the gain in efficiency from using numba. The reason is that we are working with NumPy arrays which incur a lot of overhead. We can do better by using Cython's typed memoryviews, which provide more direct access to arrays in memory. The first step is to create a NumPy array and then declare a memoryview and bind it to the NumPy array. The following code shows how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "import numpy as np\n",
    "from numpy cimport float_t\n",
    "\n",
    "def gen_cython(double x_0, int T):\n",
    "    cdef int i\n",
    "    x_np_array = np.empty(T, float)\n",
    "    cdef float_t [:] x = x_np_array\n",
    "    x[0] = x_0\n",
    "    for i in range(T-1):\n",
    "        x[i+1] = 4*x[i]*(1-x[i])\n",
    "    return np.asarray(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going over the code, `cimport` pulls in some compile-time information from NumPy. Then,\n",
    "```\n",
    "cdef float_t [:] x = x_np_array\n",
    "``` \n",
    "creates a memoryview on the NumPy array x_np_array. Finally, the `return` statement converts the memoryview back to a NumPy array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 444 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit gen_cython(0.1, int(10**5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, this helps improve the speed of the program significantly but its still not as fast as `gen_diff_numba`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Caching\n",
    "\n",
    "Suppose you are runnnig a long computation that simulates a model for given parameters and then plots a figure but midway you realize you want to change some feature of your figure and you'll have to do the thing all over again. What caching does is automatically store results at each parameterization. Thus, the second time you run the computation, it will be much faster. We will use the joblib library to do our caching (make sure you have it installed). As an example, we go back to generating a path for the difference equation but now we want to determine what fraction of the points are less than 0.1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling __main__--Users-matiasbayas-Documents-Quant Econ-__ipython-input__.gen_diff...\n",
      "gen_diff(0.2, 10000000)\n",
      "_________________________________________________________gen_diff - 8.9s, 0.1min\n",
      "0.204758079524\n",
      "TOC: Elapsed: 8.926250219345093 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.926250219345093"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import quantecon as qe\n",
    "import numpy as np\n",
    "from scipy.linalg import eigvals\n",
    "from joblib import Memory\n",
    "\n",
    "memory = Memory(cachedir='./joblib_cache')\n",
    "\n",
    "@memory.cache\n",
    "def gen_diff(x0, n):\n",
    "    x = np.empty(n+1)\n",
    "    x[0] = x0\n",
    "    for t in range(n):\n",
    "        x[t+1] = 4 * x[t] * (1 - x[t])\n",
    "    return np.mean(x < 0.1)\n",
    "\n",
    "qe.util.tic()\n",
    "n = int(1e7)\n",
    "print(gen_diff(0.2, n))\n",
    "qe.util.toc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use joblib to cache the result of calling the function `gen_diff` for a given set of parameters. With the argument `cachedir='./joblib_cache'` any call to this function results in the input and output values being stored in a subdirectory of the present working directory. If we call the function a second time, we'll see how the timing improves significantly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.204758079524\n",
      "TOC: Elapsed: 0.0017337799072265625 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0017337799072265625"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qe.util.tic()\n",
    "n = int(1e7)\n",
    "print(gen_diff(0.2, n))\n",
    "qe.util.toc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
